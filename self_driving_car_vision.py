# -*- coding: utf-8 -*-
"""Self-Driving Car Vision

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lOqAMzVLFLEYui15tf_AtJhZcLQzJvd_
"""

import cv2
import numpy as np
import os
import requests

def download_file(url, folder, filename):
    filepath = os.path.join(folder, filename)
    if not os.path.exists(filepath):
        print(f"Downloading {filename}...")
        os.makedirs(folder, exist_ok=True)
        try:
            r = requests.get(url, stream=True, timeout=20)
            r.raise_for_status()
            with open(filepath, 'wb') as f:
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)
            print("Download complete.")
        except requests.exceptions.RequestException as e:
            print(f"Error downloading {filename}: {e}")
            return None
    return filepath

def main():
    config_url = "https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3-tiny.cfg"
    weights_url = "https://pjreddie.com/media/files/yolov3-tiny.weights"
    names_url = "https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names"

    config_path = download_file(config_url, "model", "yolov3-tiny.cfg")
    weights_path = download_file(weights_url, "model", "yolov3-tiny.weights")
    names_path = download_file(names_url, "model", "coco.names")

    if not all([config_path, weights_path, names_path]):
        return

    with open(names_path, "r") as f:
        CLASSES = [line.strip() for line in f.readlines()]

    print("\nLoading YOLO model...")
    net = cv2.dnn.readNetFromDarknet(config_path, weights_path)
    print("Model loaded.")

    image_url = "https://raw.githubusercontent.com/lexfridman/mit-deep-learning/master/tutorial_driving_scene/road.jpg"
    image_path = download_file(image_url, "images", "road.jpg")

    if not image_path:
        return

    image = cv2.imread(image_path)
    (h, w) = image.shape[:2]

    ln = net.getLayerNames()
    ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]

    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)
    net.setInput(blob)
    print("\nRunning object detection...")
    layer_outputs = net.forward(ln)
    print("Detection complete.")

    boxes, confidences, class_ids = [], [], []

    for output in layer_outputs:
        for detection in output:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]
            if confidence > 0.5:
                box = detection[0:4] * np.array([w, h, w, h])
                (centerX, centerY, width, height) = box.astype("int")
                x, y = int(centerX - (width / 2)), int(centerY - (height / 2))
                boxes.append([x, y, int(width), int(height)])
                confidences.append(float(confidence))
                class_ids.append(class_id)

    idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.3)

    if len(idxs) > 0:
        for i in idxs.flatten():
            (x, y), (box_w, box_h) = (boxes[i][0], boxes[i][1]), (boxes[i][2], boxes[i][3])
            color = (0, 255, 0)
            cv2.rectangle(image, (x, y), (x + box_w, y + box_h), color, 2)
            text = f"{CLASSES[class_ids[i]]}: {confidences[i]:.4f}"
            cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    output_image_path = "output_detection.jpg"
    cv2.imwrite(output_image_path, image)
    print(f"\nDetection results saved to {output_image_path}")

if __name__ == "__main__":
    main()